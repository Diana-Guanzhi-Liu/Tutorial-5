---
title: "The Decline of Survey Response Rates"
author: Diana Liu
date: February 2 2024
email: guanzhi.liu@mail.utoronto.ca
thanks: "Code and data are available at: https://github.com/Diana-Guanzhi-Liu/Tutorial-5"
format: pdf
bibliography: /cloud/project/Ref.bib
---

```{r}
#| include: false
#| warning: false
#| message: false
### Set Up ###
# install.packages("tinytex")
# tinytex::install_tinytex()
library(tinytex)
```

# Introduction
One aspect of the editorial Special Virtual Issue on Nonresponse Rates and Nonresponse Adjustments in the Journal of Survey Statistics and Methodology focuses on the rise of nonresponse rates across 3 different methods of surveys (@CiteJSSM). These three papers each examine the response rate over time of a different survey method: telephone, online, and face-to-face through meta-analysis of published datasets of surveys using these survey methods. Face-to-face surveys and phone surveys have declining response rates over approximately the past 20 years while web surveys have an overall lower but stable response rate. Understanding the trend of response rates can help statisticians be aware of nonresponse bias in their data, costs, and devise ways of increasing their response rates for future surveys. 

# Discussion
Nonresponse rates in most face-to-face household surveys have been increasing in the US since 2000 (@CiteFace-to-face). Data collected from eight long-term studies conducted by a variety of surveying organizations show that from 2000 to 2014, response rates have been declining at around 1% per year (@CiteFace-to-face). The overall response rates for the surveys examined were around 70-80%(@CiteFace-to-face). Phone surveys from 1996 to 2015 show a similar downward trend, with response rates across 5 surveys in the US decreasing by 1.2% per year, to about 60%(@CitePhone). As for web surveys, the response rate for 45 different studies was generally stable over time, although it is on average 11% lower than other forms of surveys (@CiteWeb).

Each of the three methods of surveying has a cost and response rate trate-off. Face-to-face has the highest response rate but also the highest cost. Phone surveys are lower cost and response rate, and web surveys are the lowest cost and response rate out of the methods examined.

## Cost Implications
The two most expensive methods of surveying, face-to-face and by phone, have been experiencing declining response rates year over year. This is troublesome for statisticians planning future studies or carrying out long-term studies like the ones examined by @CiteFace-to-face because now there are fewer responses for the same cost. The downward trend of responses also imply that the amount of responses will only decrease in the future. This makes studies, especially long-term ones especially difficult to fund, as greater amount of money is needed to get the same number of responses.

Institutions that usually commission surveys such as government organizations, academic institutions, and corporations, might begin to rethink the cost-effectiveness of face-to-face and phone surveys, possibly leading to fewer surveys from being conducted and existing ones being abandoned without adequate funding. Survey designers will also need to consider which features of their surveys are cost-effective for the quality and quantity of data they provide. Literature on improving cost-effectiveness of surveys suggest identifying indicators of survey features affecting cost and quality, monitoring them during initial data collection, and changing survey features based on cost (@CiteCost). Web surveys on the other hand have a lower response rate, but makes up for it in terms of lower cost which could make them the preferred method for large-scale and long-term surveys. 

## Nonresponse Bias
While low response rates may be an indicator for nonresponse bias, it is not necessarily the case. In the face-to-face survey and phone survey articles, nonresponse bias is found to be nonsystematic and easily corrected (@CiteFace-to-face @CitePhone). The web survey article does not consider nonresponse errors, so further work is needed to determine if whether or not nonresponse indicates nonresponse errors for web surveys, and whether or not it is as easily corrected as face-to-face and phone surveys.

## Study Design
Rising nonresponse rate can be caused by a variety of things which statisticians cannot control. For example, maybe the increased rates are due to more people being reluctant to pick up the phone or answer the door to a stranger. One factor that should be examined is whether the design of a study affects its response rate. Perhaps studies can be better designed, or have certain features to increase response rate, such as being shorter or having easier to answer questions. 

\newpage
# References